{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CqtR2Fi5-vP"
      },
      "outputs": [],
      "source": [
        "# Загрузка библиотеки OpenAI-Whisper\n",
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install jiwer\n",
        "\n",
        "# Загрузка остальных библиотек\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import whisper\n",
        "import torchaudio\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "try:\n",
        "    import tensorflow  # требуется в Colab, чтобы избежать проблем с совместимостью\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# Переключение на GPU, если такое доступно\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PokfNJtOYNu"
      },
      "outputs": [],
      "source": [
        "# Загрузка модели в оперативную память\n",
        "model = whisper.load_model(\"large\")\n",
        "print(\n",
        "    f\"Model is {'multilingual' if model.is_multilingual else 'English-only'} \"\n",
        "    f\"and has {sum(np.prod(p.shape) for p in model.parameters()):,} parameters.\")\n",
        "\n",
        "# Настройка опций: временные метки — нужны, язык — русский\n",
        "options = whisper.DecodingOptions(language=\"ru\", without_timestamps=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Функция предочистки конспектного текста\n",
        "def text_preproc(prompt_file):\n",
        "    file = open(prompt_file, 'r')\n",
        "    prompt = file.read()\n",
        "    prompt = prompt.replace(\"-\\n\", \"\").replace(\"\\n\", \" \")\n",
        "    prompt = re.sub('[^А-Яа-яЁё\\s,.]', '', prompt)\n",
        "    prompt = re.sub(r'\\.{2,}', '.', prompt)\n",
        "    return prompt\n",
        "\n",
        "# Текст из конспекта стоит копировать-вставлять постранично\n",
        "# Не стоит бояться дать слишком много, чем больше исходников, тем лучше и точнее результат\n",
        "# Вставлять следует текст по смежным темам — корпус слов стоит дать соответствующий\n",
        "\n",
        "# Очистка и вывод для проверки\n",
        "prompt_transcribe = text_preproc('prompt.txt')\n",
        "prompt_transcribe"
      ],
      "metadata": {
        "id": "vYihKvRk-lJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Непосредственно транскрибация\n",
        "result = model.transcribe(\"grishunin_35m1s_40m20s_processed.mp3\", initial_prompt=prompt_transcribe)"
      ],
      "metadata": {
        "id": "SSoapVLoaPI6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Экспорт текста целиком в файл\n",
        "export_file = open(\"result.txt\", \"w\")\n",
        "export_file.write(result['text'])\n",
        "export_file.close()\n",
        "\n",
        "# Экспорт текста с таймкодами в файл\n",
        "with open('result_timecodes.txt', 'w', encoding='utf-8') as file:\n",
        "    for segment in result['segments']:\n",
        "        start_time = segment['start']\n",
        "        end_time = segment['end']\n",
        "        text = segment['text']\n",
        "\n",
        "        file.write(f\"{start_time}s — {end_time}s\\n\")\n",
        "        file.write(f\"{text}\\n\\n\")"
      ],
      "metadata": {
        "id": "Zrzv739YyBZa"
      },
      "execution_count": 15,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}